{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Work of Machine Learning Discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is VERB aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'You finded the book that I told you, Carla?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando cada parte do texto como string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You', 'finded', 'the', 'book', 'that', 'I', 'told', 'you,', 'Carla?']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegando cada token e mostrando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[You, finded, the, book, that, I, told, you, ,, Carla, ?]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in doc2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegando os tokens como strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You', 'finded', 'the', 'book', 'that', 'I', 'told', 'you', ',', 'Carla', '?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegando apenas as palavras de um texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You', 'finded', 'the', 'book', 'that', 'I', 'told', 'you', 'Carla']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc2 if not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '?']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc2 if token.is_punct]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for token in doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63271797"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you | I\n",
    "tokens[0].similarity(tokens[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04096923"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you | book\n",
    "tokens[0].similarity(tokens[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de classes gramaticais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('You', 'PRON'),\n",
       " ('finded', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('book', 'NOUN'),\n",
       " ('that', 'ADJ'),\n",
       " ('I', 'PRON'),\n",
       " ('told', 'VERB'),\n",
       " ('you', 'PRON'),\n",
       " (',', 'PUNCT'),\n",
       " ('Carla', 'PROPN'),\n",
       " ('?', 'PUNCT')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.orth_, token.pos_) for token in doc2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo a lematização \n",
    "Isso funciona para textos que podem ter diversas conjufações e tempos verbais, assim ele somente pega a raíz da palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['find', 'tell']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in doc2 if token.pos_ == 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'knew, know')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['know', 'know']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in doc2 if token.pos_ == 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifica se uma palavra é ancestral de outra\n",
    "doc2 = nlp(u'find finded')\n",
    "tokens = [token for token in doc2]\n",
    "tokens[0].is_ancestor(tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entidades!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Levi Carneiro one of the best writers in Brazil, was an president of the Brasilian Academy of Letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Levi Carneiro, 'PERSON'),\n",
       " (Brazil, 'GPE'),\n",
       " (the Brasilian Academy of Letters, 'ORG')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(entity, entity.label_) for entity in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Barack Obama, 'PERSON'),\n",
       " (American, 'NORP'),\n",
       " (, 'GPE'),\n",
       " (44th, 'ORDINAL'),\n",
       " (the United States, 'GPE'),\n",
       " (2009 to 2017, 'DATE'),\n",
       " (first, 'ORDINAL'),\n",
       " (\n",
       "  African American, 'NORP'),\n",
       " (, 'GPE'),\n",
       " (first, 'ORDINAL'),\n",
       " (United States, 'GPE')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo maior\n",
    "wiki_obama = \"\"\"Barack Obama is an American politician who served as\n",
    "the 44th President of the United States from 2009 to 2017. He is the first\n",
    "African American to have served as president,\n",
    "as well as the first born outside the contiguous United States.\"\"\"\n",
    "nlp_obama = nlp(wiki_obama)\n",
    "[(entity, entity.label_) for entity in nlp_obama.ents]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
